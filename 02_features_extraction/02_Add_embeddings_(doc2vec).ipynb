{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b82ca7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "nlp_core = spacy.load(\"pl_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "12590b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e53c32f",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1adf5c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/wisio/a-gentle-introduction-to-doc2vec-db3e8c0cce5e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecd4314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/scrapped/demagog_features.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d27fd56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assestment</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>sentiment_all</th>\n",
       "      <th>sentiment_avg</th>\n",
       "      <th>uniq_words</th>\n",
       "      <th>uniq_lemm</th>\n",
       "      <th>err</th>\n",
       "      <th>net</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADV</th>\n",
       "      <th>NOUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nieweryfikowalne</td>\n",
       "      <td>Generalnie, jak pokazują dane i szacunki, to n...</td>\n",
       "      <td>Generalnie, jak pokazują dane i szacunki, to ...</td>\n",
       "      <td>-0.008995</td>\n",
       "      <td>-0.083364</td>\n",
       "      <td>33.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.212121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prawda</td>\n",
       "      <td>Według ich (ukraińskich – przyp. Demagog) dany...</td>\n",
       "      <td>Według ich ukraińskich danych w Polsce, czy n...</td>\n",
       "      <td>-0.008995</td>\n",
       "      <td>-0.008995</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fałsz</td>\n",
       "      <td>Po pierwsze, jest 51,25 proc. ludzi tylko zasz...</td>\n",
       "      <td>Po pierwsze, jest 51,25 proc. ludzi tylko zasz...</td>\n",
       "      <td>-0.008995</td>\n",
       "      <td>-0.045055</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prawda</td>\n",
       "      <td>Po pierwsze, system bankowy w Polsce, no, ma s...</td>\n",
       "      <td>Po pierwsze, system bankowy w Polsce, no, ma s...</td>\n",
       "      <td>0.026141</td>\n",
       "      <td>-0.081037</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fałsz</td>\n",
       "      <td>Magazyny gazu mamy pełne tylko w 60%, bo w lis...</td>\n",
       "      <td>Magazyny gazu mamy pełne tylko w 60%, bo w lis...</td>\n",
       "      <td>-0.024012</td>\n",
       "      <td>-0.024012</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         assestment                                               text  \\\n",
       "0  Nieweryfikowalne  Generalnie, jak pokazują dane i szacunki, to n...   \n",
       "1            Prawda  Według ich (ukraińskich – przyp. Demagog) dany...   \n",
       "2             Fałsz  Po pierwsze, jest 51,25 proc. ludzi tylko zasz...   \n",
       "3            Prawda  Po pierwsze, system bankowy w Polsce, no, ma s...   \n",
       "4             Fałsz  Magazyny gazu mamy pełne tylko w 60%, bo w lis...   \n",
       "\n",
       "                                          text_clean  sentiment_all  \\\n",
       "0  Generalnie, jak pokazują dane i szacunki, to ...      -0.008995   \n",
       "1  Według ich ukraińskich danych w Polsce, czy n...      -0.008995   \n",
       "2  Po pierwsze, jest 51,25 proc. ludzi tylko zasz...      -0.008995   \n",
       "3  Po pierwsze, system bankowy w Polsce, no, ma s...       0.026141   \n",
       "4  Magazyny gazu mamy pełne tylko w 60%, bo w lis...      -0.024012   \n",
       "\n",
       "   sentiment_avg  uniq_words  uniq_lemm  err  net       ADJ       ADV  \\\n",
       "0      -0.083364        33.0       29.0  3.0  1.0  0.212121  0.060606   \n",
       "1      -0.008995        18.0       17.0  0.0  3.0  0.055556  0.055556   \n",
       "2      -0.045055        24.0       24.0  0.0  1.0  0.125000  0.125000   \n",
       "3      -0.081037        19.0       19.0  1.0  1.0  0.157895  0.000000   \n",
       "4      -0.024012        23.0       23.0  2.0  2.0  0.086957  0.000000   \n",
       "\n",
       "       NOUN  \n",
       "0  0.212121  \n",
       "1  0.166667  \n",
       "2  0.083333  \n",
       "3  0.263158  \n",
       "4  0.173913  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3539a34e",
   "metadata": {},
   "source": [
    "## Create tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "096389b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nlp_core.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9cdc917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(txt):\n",
    "    doc = nlp_core(txt)\n",
    "    \n",
    "    words = [\n",
    "        token.lemma_.lower()\n",
    "        for token in doc \n",
    "        if \n",
    "            not token.is_stop \n",
    "            and not token.is_punct \n",
    "            and not token.is_stop \n",
    "            and token.text != ' '\n",
    "            and token.lemma_ not in stopwords]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d9545b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4891/4891 [00:37<00:00, 132.10it/s]\n"
     ]
    }
   ],
   "source": [
    "df['tokens'] = df['text_clean'].progress_apply(lambda x: tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "abd55964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['assestment', 'text', 'text_clean', 'sentiment_all', 'sentiment_avg',\n",
       "       'uniq_words', 'uniq_lemm', 'err', 'net', 'ADJ', 'ADV', 'NOUN',\n",
       "       'tokens'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8686bc26",
   "metadata": {},
   "source": [
    "## Create documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "3a3cb8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(doc, [asess]) for doc, asess in zip(df['tokens'].values, df['assestment'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d5a4b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test/train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4eb4fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    documents, df['assestment'].values, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "34b2b7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3276"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ed3ef1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1615"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b74ce98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4891"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6957df49",
   "metadata": {},
   "source": [
    "## Distributed Bag of Words (DBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1adb9746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/multi-class-text-classification-with-doc2vec-logistic-regression-9da9947b43f4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "1da7558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "c98abf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 3276/3276 [00:00<00:00, 3718684.68it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=vec_size, negative=5, hs=0, min_count=2, sample = 0, workers=-1)\n",
    "model_dbow.build_vocab([x for x in tqdm(X_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "50f39b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 100)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dbow.dv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "316c8ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 30/30 [00:00<00:00, 282.58it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(30)):\n",
    "    model_dbow.train(utils.shuffle([x for x in X_train]), total_examples=len(X_train), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "0454f92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 100)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dbow.dv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "ff584c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.82010522e-03,  1.32367015e-03, -1.21010304e-03,  2.02521449e-03,\n",
       "        8.15075065e-04, -4.58522147e-04, -4.96143111e-05,  5.10455342e-04,\n",
       "        4.70304536e-03, -1.61909455e-04,  7.89680460e-04,  2.62736506e-03,\n",
       "       -2.64167134e-03, -2.79070623e-03,  2.85474490e-03,  3.07439500e-03,\n",
       "       -3.50084715e-03, -5.42388530e-04, -3.51120927e-03,  3.66789405e-03,\n",
       "        1.77271187e-03, -3.68622132e-03,  3.03104520e-03, -4.04267386e-03,\n",
       "        3.14321765e-03,  2.06956262e-04, -3.70119815e-04,  1.61230506e-03,\n",
       "        4.40544263e-03, -4.88106674e-03,  2.16436386e-03, -4.66635538e-04,\n",
       "        4.74678632e-03, -4.45929402e-03,  1.30818959e-03, -7.92977226e-05,\n",
       "       -1.40052917e-03, -3.27100279e-03, -2.45396188e-03, -4.82668262e-03,\n",
       "        2.60559982e-03, -1.42347068e-03, -7.10540393e-04,  3.08878429e-04,\n",
       "       -4.78844391e-03, -2.96823261e-03, -1.11795333e-03, -2.46288534e-03,\n",
       "       -1.21040014e-03,  1.34949747e-03,  3.96676734e-03,  1.73692708e-04,\n",
       "       -4.35647927e-03, -1.32120517e-03,  4.99207713e-03,  1.86786114e-03,\n",
       "       -4.34960239e-03,  3.22699547e-04,  1.84120121e-03, -1.23948220e-03,\n",
       "       -2.28889287e-04,  2.69261538e-03,  2.94977659e-03,  4.24959464e-03,\n",
       "       -4.75000311e-03,  3.54336924e-03,  2.37896852e-03,  1.68994546e-03,\n",
       "       -3.54942679e-03, -3.48721375e-03,  1.34872203e-03,  4.92311083e-03,\n",
       "        1.47124473e-03,  3.41332844e-03,  7.27416249e-04,  1.60935696e-03,\n",
       "        4.29533143e-03,  4.45061317e-03, -3.89230251e-03, -2.33800476e-03,\n",
       "       -4.08551097e-03, -1.80028670e-04, -7.29946187e-04, -3.19699058e-03,\n",
       "        9.05581110e-04, -3.92362894e-03,  4.00601048e-03,  2.67014862e-03,\n",
       "        1.75175304e-03,  3.37396795e-03,  4.36172122e-03, -2.06603575e-03,\n",
       "       -1.09016895e-04,  4.43498557e-03,  4.35401034e-03, -4.22814483e-04,\n",
       "       -4.39986493e-03,  2.31677410e-03, -3.56872194e-03,  1.88065766e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dbow.infer_vector(X_train[0][0], epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94418bcd",
   "metadata": {},
   "source": [
    "## Distributed Memory (DM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "88d33073",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 3276/3276 [00:00<00:00, 3223965.25it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dmm = Doc2Vec(dm=1, dm_mean=1, vector_size=vec_size, window=10, negative=5, min_count=1, workers=5, alpha=0.065, min_alpha=0.065)\n",
    "model_dmm.build_vocab([x for x in tqdm(X_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "b112fabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [00:13<00:00,  2.15it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(30)):\n",
    "    model_dmm.train(utils.shuffle([x for x in X_train]), total_examples=len(X_train), epochs=1)\n",
    "    model_dmm.alpha -= 0.002\n",
    "    model_dmm.min_alpha = model_dmm.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "b50dbf31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04535777, -0.06786642, -0.12222414,  0.08527846,  0.01722405,\n",
       "        0.02920332, -0.05554929,  0.00576284, -0.06077851,  0.07339821,\n",
       "       -0.0457494 ,  0.00075715, -0.03116681, -0.01983386,  0.02832681,\n",
       "       -0.0997513 ,  0.05005576,  0.04944408, -0.10878636, -0.09536558,\n",
       "        0.03136603,  0.06024092, -0.07715973,  0.02640513,  0.01322494,\n",
       "       -0.0061265 , -0.09081481, -0.10941311,  0.00344852, -0.13273138,\n",
       "        0.09561838,  0.01823818, -0.06772862, -0.07144389, -0.08853121,\n",
       "        0.11904304, -0.01521839, -0.08974492, -0.0828031 , -0.04743225,\n",
       "        0.02988441, -0.07270483,  0.02241149, -0.06001237, -0.0084103 ,\n",
       "       -0.02019314, -0.05067368, -0.0134854 ,  0.02245815, -0.08582152,\n",
       "       -0.01512442, -0.06741744, -0.08959883, -0.12613893, -0.0510443 ,\n",
       "        0.10416008, -0.02184371,  0.04934153, -0.06870003,  0.0645615 ,\n",
       "        0.0735912 ,  0.09319782,  0.0672884 , -0.07830662, -0.01436684,\n",
       "        0.01647807,  0.02695496,  0.00069515, -0.12516475, -0.04912638,\n",
       "       -0.03621904, -0.01128067, -0.05928142, -0.07237192, -0.01280024,\n",
       "        0.00029381, -0.07989246, -0.03960557, -0.0220673 ,  0.01427806,\n",
       "        0.04151716,  0.05992834, -0.11153322, -0.00167434,  0.01530847,\n",
       "        0.07311589,  0.04184185, -0.0216598 ,  0.03497532, -0.03798626,\n",
       "       -0.07823175,  0.10465878, -0.05628607, -0.00465189, -0.05714984,\n",
       "        0.11972333,  0.04692384, -0.04744755,  0.09789723,  0.044337  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dmm.infer_vector(X_train[0][0], epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88a4a1f",
   "metadata": {},
   "source": [
    "## Model Pairing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "24dca453",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = ConcatenatedDoc2Vec([model_dbow, model_dmm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "8e3f1bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train(X_train, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "5393bb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaggedDocument(['eurostat', 'umieścić', 'polskę', 'drugi', 'miejsce', 'ue', 'jeśli', 'chodzić', 'przyjmować', 'uchodźców', 'padła', 'liczba', '400', 'osób', 'oczywiście', 'są', 'człowiek', 'ukraina'], ['Manipulacja'])\n"
     ]
    }
   ],
   "source": [
    "model = model_dbow\n",
    "\n",
    "doc_id = 36\n",
    "# inferred_vector = model_loaded.infer_vector(['酒精', '用', '啥', '稀释'])\n",
    "inferred_vector = model.infer_vector(X_train[doc_id].words)\n",
    "sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "\n",
    "print(X_train[36])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "004cf376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('istotny', 0.3358919322490692),\n",
       " ('częścią', 0.32700976729393005),\n",
       " ('podlaski', 0.31398558616638184),\n",
       " ('singapur', 0.2944522798061371),\n",
       " ('westerplatte', 0.2781083583831787),\n",
       " ('chociażby', 0.2775360345840454),\n",
       " ('złożć', 0.27565690875053406),\n",
       " ('zatrzymać', 0.2735329866409302),\n",
       " ('rak', 0.2683793902397156),\n",
       " ('umieścić', 0.2677927315235138)]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dbow.wv.most_similar('morawiecki')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4917b1a",
   "metadata": {},
   "source": [
    "## Apply embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b83f40ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[ 'e'+str(i) for i in range(vec_size*2) ]] = [new_model.infer_vector(d[0]).tolist() for d in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "404278c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_learn = df[\n",
    "    ['assestment', 'text_clean', \n",
    "     'sentiment_all', 'sentiment_avg',\n",
    "     'uniq_words', 'uniq_lemm', 'err', 'net', 'ADJ', 'ADV', 'NOUN',\n",
    "     'e0', 'e1', 'e2', 'e3', 'e4',\n",
    "     'e5', 'e6', 'e7', 'e8', 'e9']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "885c1126",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_learn.to_csv('../datasets/scrapped/demagog_features_emb.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18094d35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
