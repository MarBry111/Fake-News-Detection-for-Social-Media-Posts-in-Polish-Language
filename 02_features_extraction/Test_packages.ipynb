{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beffabc2",
   "metadata": {},
   "source": [
    "- https://github.com/ksopyla/awesome-nlp-polish\n",
    "- Sentiment: https://pypi.org/project/sentimentpl/\n",
    "- Auto correct: https://github.com/filyp/autocorrect\n",
    "- other: https://github.com/sdadas/polish-nlp-resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1652209b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sentimentpl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9379/1857435162.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msentimentpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentimentPLModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautocorrect\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpeller\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHerbertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRobertaModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sentimentpl'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from sentimentpl.models import SentimentPLModel\n",
    "from autocorrect import Speller\n",
    "from transformers import HerbertTokenizer, RobertaModel\n",
    "#import polyglot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48ff0685",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'pl_core_news_lg'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9379/2483465439.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlp_core\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pl_core_news_lg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/master_ds/lib/python3.7/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/master_ds/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exists'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Path or Path-like to model data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'pl_core_news_lg'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "nlp_core = spacy.load(\"pl_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "216caffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentPLModel(from_pretrained='latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "406c7881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spell = Speller('pl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe28bad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLMTokenizer'. \n",
      "The class this function is called from is 'HerbertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer_herbert = HerbertTokenizer.from_pretrained(\"allegro/herbert-klej-cased-tokenizer-v1\")\n",
    "model_roberta = RobertaModel.from_pretrained(\"allegro/herbert-klej-cased-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df966dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp_pl = spacy.load('pl_spacy_model') # or spacy.load('pl_spacy_model_morfeusz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d469a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp_core(\"Nienawidzę tego robić, tym bardziej że robię to codziennie. Ale przynajmniej mam łatwą pracę w Google.\")\n",
    "lemmas_list = []\n",
    "tokens_list = []\n",
    "sentiments_list = []\n",
    "embeddings_list = []\n",
    "\n",
    "error_n = 0\n",
    "\n",
    "adj_n = 0\n",
    "adv_n = 0\n",
    "noun_n = 0\n",
    "ent_n = 0\n",
    "\n",
    "print(doc.text)\n",
    "print(f'Sentiment: {model(doc.text).item()}\\n')\n",
    "\n",
    "for i, sent in enumerate(doc.sents):\n",
    "    s = model(sent.text).item()\n",
    "    print(f'Sentiment sentence {i}: {s}')  \n",
    "    sentiments_list.append(s)\n",
    "print()\n",
    "print(f'AVG sentiment of sentences: {np.mean(sentiments_list)}\\n')\n",
    "\n",
    "\n",
    "for token in doc:\n",
    "    #print(token.text, token.pos_, token.dep_, token.lemma_)\n",
    "    if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "        lemmas_list.append(token.lemma_)\n",
    "        tokens_list.append(token.text)\n",
    "        corrected = spell(token.text)\n",
    "        if corrected != token.text:\n",
    "            error_n += 1\n",
    "    \n",
    "    if token.pos_ == 'ADJ': \n",
    "        adj_n += 1\n",
    "    elif token.pos_ == 'ADV':\n",
    "        adv_n += 1\n",
    "    elif token.pos_ == 'NOUN':\n",
    "        noun_n += 1\n",
    "        \n",
    "for ent in doc.ents:\n",
    "    #print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "    ent_n += 1\n",
    "    \n",
    "tokens_list = list(set(tokens_list))\n",
    "lemmas_list = list(set(lemmas_list))\n",
    "\n",
    "print('Unique words:', len(tokens_list))\n",
    "print('Unique lemmas:', len(lemmas_list), '\\n')\n",
    "print('Errors:', error_n)\n",
    "print('Named entities:', ent_n, '\\n')\n",
    "print('ADJ:', adj_n, adj_n/len(tokens_list))\n",
    "print('ADV:', adv_n, adv_n/len(tokens_list))\n",
    "print('NOUN:', noun_n, noun_n/len(tokens_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e3519773",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer_herbert.encode(doc.text, return_tensors=\"pt\")\n",
    "outputs = model_roberta(encoded_input)\n",
    "embeddings = outputs['pooler_output'].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8cd4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
