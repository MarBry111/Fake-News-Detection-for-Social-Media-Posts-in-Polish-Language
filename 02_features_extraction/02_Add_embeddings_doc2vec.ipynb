{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b82ca7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "nlp_core = spacy.load(\"pl_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12590b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e53c32f",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1adf5c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/wisio/a-gentle-introduction-to-doc2vec-db3e8c0cce5e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecd4314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/scrapped/demagog_features.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d27fd56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assestment</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>sentiment_all</th>\n",
       "      <th>sentiment_avg</th>\n",
       "      <th>uniq_words</th>\n",
       "      <th>uniq_lemm</th>\n",
       "      <th>err</th>\n",
       "      <th>net</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADV</th>\n",
       "      <th>NOUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nieweryfikowalne</td>\n",
       "      <td>Generalnie, jak pokazują dane i szacunki, to n...</td>\n",
       "      <td>Generalnie, jak pokazują dane i szacunki, to ...</td>\n",
       "      <td>-0.008995</td>\n",
       "      <td>-0.083364</td>\n",
       "      <td>33.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.212121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prawda</td>\n",
       "      <td>Według ich (ukraińskich – przyp. Demagog) dany...</td>\n",
       "      <td>Według ich ukraińskich danych w Polsce, czy n...</td>\n",
       "      <td>-0.008995</td>\n",
       "      <td>-0.008995</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fałsz</td>\n",
       "      <td>Po pierwsze, jest 51,25 proc. ludzi tylko zasz...</td>\n",
       "      <td>Po pierwsze, jest 51,25 proc. ludzi tylko zasz...</td>\n",
       "      <td>-0.008995</td>\n",
       "      <td>-0.045055</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prawda</td>\n",
       "      <td>Po pierwsze, system bankowy w Polsce, no, ma s...</td>\n",
       "      <td>Po pierwsze, system bankowy w Polsce, no, ma s...</td>\n",
       "      <td>0.026141</td>\n",
       "      <td>-0.081037</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fałsz</td>\n",
       "      <td>Magazyny gazu mamy pełne tylko w 60%, bo w lis...</td>\n",
       "      <td>Magazyny gazu mamy pełne tylko w 60%, bo w lis...</td>\n",
       "      <td>-0.024012</td>\n",
       "      <td>-0.024012</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         assestment                                               text  \\\n",
       "0  Nieweryfikowalne  Generalnie, jak pokazują dane i szacunki, to n...   \n",
       "1            Prawda  Według ich (ukraińskich – przyp. Demagog) dany...   \n",
       "2             Fałsz  Po pierwsze, jest 51,25 proc. ludzi tylko zasz...   \n",
       "3            Prawda  Po pierwsze, system bankowy w Polsce, no, ma s...   \n",
       "4             Fałsz  Magazyny gazu mamy pełne tylko w 60%, bo w lis...   \n",
       "\n",
       "                                          text_clean  sentiment_all  \\\n",
       "0  Generalnie, jak pokazują dane i szacunki, to ...      -0.008995   \n",
       "1  Według ich ukraińskich danych w Polsce, czy n...      -0.008995   \n",
       "2  Po pierwsze, jest 51,25 proc. ludzi tylko zasz...      -0.008995   \n",
       "3  Po pierwsze, system bankowy w Polsce, no, ma s...       0.026141   \n",
       "4  Magazyny gazu mamy pełne tylko w 60%, bo w lis...      -0.024012   \n",
       "\n",
       "   sentiment_avg  uniq_words  uniq_lemm  err  net       ADJ       ADV  \\\n",
       "0      -0.083364        33.0       29.0  3.0  1.0  0.212121  0.060606   \n",
       "1      -0.008995        18.0       17.0  0.0  3.0  0.055556  0.055556   \n",
       "2      -0.045055        24.0       24.0  0.0  1.0  0.125000  0.125000   \n",
       "3      -0.081037        19.0       19.0  1.0  1.0  0.157895  0.000000   \n",
       "4      -0.024012        23.0       23.0  2.0  2.0  0.086957  0.000000   \n",
       "\n",
       "       NOUN  \n",
       "0  0.212121  \n",
       "1  0.166667  \n",
       "2  0.083333  \n",
       "3  0.263158  \n",
       "4  0.173913  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3539a34e",
   "metadata": {},
   "source": [
    "## Create tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "096389b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nlp_core.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9cdc917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(txt):\n",
    "    doc = nlp_core(txt)\n",
    "    \n",
    "    words = [\n",
    "        token.lemma_ \n",
    "        for token in doc \n",
    "        if \n",
    "            not token.is_stop \n",
    "            and not token.is_punct \n",
    "            and not token.is_stop \n",
    "            and token.text != ' '\n",
    "            and token.lemma_ not in stopwords]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d9545b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4891/4891 [00:37<00:00, 131.59it/s]\n"
     ]
    }
   ],
   "source": [
    "df['tokens'] = df['text_clean'].progress_apply(lambda x: tokenize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8686bc26",
   "metadata": {},
   "source": [
    "## Create documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3a3cb8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(df['tokens'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d5a4b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test/train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4eb4fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    documents, df['assestment'].values, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9cfb819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(X_train, vector_size=5, window=2, min_count=1, workers=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e459992e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8936/2021273564.py:1: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  model.docvecs[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.10461631, -0.11958256, -0.1976151 ,  0.1710569 ,  0.0713223 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8e3f1bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(X_train, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b504aeb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['Polska', 'najniższą', 'ilość', 'bezrobotny', 'zdawać', 'się', 'że', 'Litwa'], tags=[751])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1bfc4662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07761909, 0.025082  , 0.0071852 , 0.05433891, 0.08226164],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer_vector(X_test[0][0]) # generate a vector for an unseen sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "08afcdec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01312388, -0.09644593, -0.02507035,  0.06522723,  0.05922448],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer_vector(X_train[0][0])# generate a vector for an unseen sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4917b1a",
   "metadata": {},
   "source": [
    "## Apply embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b83f40ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[ 'e'+str(i) for i in range(5) ]] = [model.infer_vector(d[0]).tolist() for d in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "404278c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_learn = df[\n",
    "    ['assestment', 'text_clean', \n",
    "     'sentiment_all', 'sentiment_avg',\n",
    "     'uniq_words', 'uniq_lemm', 'err', 'net', 'ADJ', 'ADV', 'NOUN',\n",
    "     'e0', 'e1', 'e2', 'e3', 'e4']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "885c1126",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_learn.to_csv('../datasets/scrapped/demagog_features_emb.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18094d35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
